{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML (Titanic Survival Prediction Project)\n",
        "\n",
        "Importing Dependencies needed to to complete the project:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries needed\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.20.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1613596353658
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the authentication using the Workspace method \"from_config\"\n",
        "Workspace.from_config()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AGQ5R88M5 to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "Workspace.create(name='quick-starts-ws-139092', subscription_id='2c48c51c-bd47-40d4-abbe-fb8eabd19c8c', resource_group='aml-quickstarts-139092')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613596385274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create workspace\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1613596388858
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Experiment\n",
        "\n",
        "experiment_name = 'automl-experiment-1'\n",
        "project_folder = './pipeline-project'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Experiment(Name: automl-experiment-1,\nWorkspace: quick-starts-ws-139092)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-experiment-1</td><td>quick-starts-ws-139092</td><td><a href=\"https://ml.azure.com/experiments/automl-experiment-1?wsid=/subscriptions/2c48c51c-bd47-40d4-abbe-fb8eabd19c8c/resourcegroups/aml-quickstarts-139092/workspaces/quick-starts-ws-139092\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1613596395379
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Overview:\n",
        "\n",
        "As you probably have guessed from the project title we will be working with the \"Titanic Dataset\" which is already a classical dataset to learn Machine Learning.\n",
        "\n",
        "The main task for this project will be to build a predictive model that answers the question: “what sorts of people were more likely to survive?” To answer the above stated question we are going to give the model different input variables such as age, type of cabin the passanger had, etc"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "target_column_name = 'demand'\r\n",
        "time_column_name = 'timeStamp'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613596577386
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the dataset\n",
        "key = \"Energy Dataset 2\"\n",
        "description_text = \"Forecasting Energy Dataset\"\n",
        "\n",
        "dataset = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/nyc_energy.csv\").with_timestamp_columns(fine_grain_timestamp=time_column_name)\n",
        "\n",
        "#Register Dataset\n",
        "dataset = dataset.register(workspace=ws,\n",
        "                           name=key,\n",
        "                           description=description_text)\n",
        "\n",
        "#Create a df out of the registered dataset\n",
        "dataset = dataset.to_pandas_dataframe()\n",
        "dataset.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "             demand        precip          temp\ncount  49124.000000  48975.000000  49019.000000\nmean    6067.447361      0.003522     55.520428\nstd     1285.607657      0.022841     17.704848\nmin     2859.600000      0.000000      0.330000\n25%     5133.862250      0.000000     41.415000\n50%     6020.071000      0.000000     56.260000\n75%     6684.300000      0.000000     70.540000\nmax    11456.000000      0.905100     97.260000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>demand</th>\n      <th>precip</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>49124.000000</td>\n      <td>48975.000000</td>\n      <td>49019.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6067.447361</td>\n      <td>0.003522</td>\n      <td>55.520428</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1285.607657</td>\n      <td>0.022841</td>\n      <td>17.704848</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2859.600000</td>\n      <td>0.000000</td>\n      <td>0.330000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5133.862250</td>\n      <td>0.000000</td>\n      <td>41.415000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6020.071000</td>\n      <td>0.000000</td>\n      <td>56.260000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6684.300000</td>\n      <td>0.000000</td>\n      <td>70.540000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>11456.000000</td>\n      <td>0.905100</td>\n      <td>97.260000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1613596731948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "                              timeStamp  demand  precip   temp\n2012-01-01 00:00:00 2012-01-01 00:00:00  4937.5     0.0  46.13\n2012-01-01 01:00:00 2012-01-01 01:00:00  4752.1     0.0  45.89\n2012-01-01 02:00:00 2012-01-01 02:00:00  4542.6     0.0  45.04\n2012-01-01 03:00:00 2012-01-01 03:00:00  4357.7     0.0  45.03\n2012-01-01 04:00:00 2012-01-01 04:00:00  4275.5     0.0  42.61",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timeStamp</th>\n      <th>demand</th>\n      <th>precip</th>\n      <th>temp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-01-01 00:00:00</th>\n      <td>2012-01-01 00:00:00</td>\n      <td>4937.5</td>\n      <td>0.0</td>\n      <td>46.13</td>\n    </tr>\n    <tr>\n      <th>2012-01-01 01:00:00</th>\n      <td>2012-01-01 01:00:00</td>\n      <td>4752.1</td>\n      <td>0.0</td>\n      <td>45.89</td>\n    </tr>\n    <tr>\n      <th>2012-01-01 02:00:00</th>\n      <td>2012-01-01 02:00:00</td>\n      <td>4542.6</td>\n      <td>0.0</td>\n      <td>45.04</td>\n    </tr>\n    <tr>\n      <th>2012-01-01 03:00:00</th>\n      <td>2012-01-01 03:00:00</td>\n      <td>4357.7</td>\n      <td>0.0</td>\n      <td>45.03</td>\n    </tr>\n    <tr>\n      <th>2012-01-01 04:00:00</th>\n      <td>2012-01-01 04:00:00</td>\n      <td>4275.5</td>\n      <td>0.0</td>\n      <td>42.61</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613596782639
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Be sure to have the compute target setup\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"notebook139092\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           min_nodes=1,\n",
        "                                                           max_nodes=6)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "\n",
            "Running\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1613596761352
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\r\n",
        "# Cut off the end of the dataset due to large number of nan values\r\n",
        "#dataset = dataset.time_before(datetime(2017, 10, 10, 5))\r\n",
        "zeit = (datetime(2017,10,10,5))\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613597218696
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[dataset.timeStamp < zeit].copy()"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1613597298626
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Data:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Import your clean data function from the train.py file\n",
        "from train import clean_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801584314
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply the function\n",
        "x, y = clean_data(dataset)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801590391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the features\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801597126
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create scaler\n",
        "variables = x.columns.tolist()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x[variables]) \n",
        "\n",
        "x = scaler.transform(x[variables])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801601773
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.DataFrame(x,columns=variables)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612801607638
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state=0)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801614270
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bring them together them again\n",
        "dataset = pd.concat([x_train,y_train],axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801620929
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801626363
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To train the model we need a TabularDataset and not a dataframe, therefore the current df will be converterd \n",
        "#into a TabularDataset:\n",
        "\n",
        "#Convert the dataframe into a csv\n",
        "local_path = 'prepared.csv'\n",
        "\n",
        "#Save it locally\n",
        "dataset.to_csv(local_path,index=None)\n",
        "\n",
        "#Generate the a datastore object which is the the default datastore\n",
        "datastore = ws.get_default_datastore()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801633010
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload the dataframe which was previosly converted into a csv\n",
        "datastore.upload(src_dir='.', target_path='data')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801636555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For the sake of checking; check the path\n",
        "datastore.path()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801641127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now the uploaded file will be transformed into a Tabular dataset and store in a varible named 'training_dataset'\n",
        "training_dataset = Dataset.Tabular.from_delimited_files(path= [(datastore,('data/prepared.csv'))])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801648178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's visualize the data:\n",
        "training_dataset.to_pandas_dataframe().head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801654940
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "Below we will chose the automl settings and cofiguration"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the automl settings which will be used as argurments in the automl config\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "#Create the automl_config\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data=training_dataset,\n",
        "                             label_column_name=\"survived\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612801675790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Submitt the experiment\n",
        "\n",
        "automl_run = experiment.submit(automl_config,show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612716689612
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Additional Run Details\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(automl_run).show()\n",
        "\n",
        "# wait for completion\n",
        "automl_run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612802994779
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get generic outputs from the automl_run\n",
        "automl_run.get_output()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612803039483
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the best model outputs\n",
        "best_automl_run, best_model = automl_run.get_output()\n",
        "\n",
        "\n",
        "# Retrieve the best automl run model\n",
        "print('Best AutoML run: ', best_automl_run)\n",
        "print('Best AutoML model :', best_model)\n",
        "\n",
        "# get best model and display properties\n",
        "model_name = best_automl_run.properties['model_name']\n",
        "print('Best_model name: ', model_name)\n",
        "\n",
        "# display all the properties of the best model\n",
        "best_automl_run.get_properties()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612803063173
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the best model id\n",
        "print(best_automl_run.id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612803097305
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the best AutoML model\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(best_model, 'best_automl_model.pkl')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612803119090
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register best AutoML model for future deployment\n",
        "\n",
        "from azureml.core.model import Model\n",
        "description = 'AutoML Model trained on the titanic dataset'\n",
        "tags = {'area': 'data science beginners', 'type': 'classification'}\n",
        "\n",
        "automl_model = Model.register(workspace =ws,\n",
        "                              model_name = 'best-titanicMLmodel',\n",
        "                              model_path = 'best_automl_model.pkl',\n",
        "                             description = description, tags = tags)\n",
        "\n",
        "print('AutoML RunID: ', automl_run.id, sep='\\t')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612803144972
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare deploying of the model as a web service\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup Environment\n",
        "env = Environment.get(workspace=ws, name='AzureML-AutoML')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806348039
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chekc environment dependencies\n",
        "print(\"packages\", env.python.conda_dependencies.serialize_to_string())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806352240
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup the inference and aci config\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4, enable_app_insights=True, auth_enabled=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806374855
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Deploy\n",
        "service_name = 'my-ml-service'\n",
        "\n",
        "model = Model(ws,name='best-titanicMLmodel')\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name=service_name,\n",
        "                       models=[model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806525913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806543093
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print service state\n",
        "print(service.state)\n",
        "# print scoring URI\n",
        "print('scoring URI: ' + service.scoring_uri)\n",
        "# print Swagger URI\n",
        "print('Swagger URI: ' + service.swagger_uri)\n",
        "# retrieve authentication keys\n",
        "primary, secondary = service.get_keys()\n",
        "# print primary authenticaton key\n",
        "print('Primary Authentication Key: ' + primary)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612806554530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Store the uri's in variables:\n",
        "\n",
        "scoring_uri = 'http://87897773-cb15-40d5-ba0d-ba8285d8f467.southcentralus.azurecontainer.io/score'\n",
        "\n",
        "key = 'iBX2glUB3xcahOndX5AW62WoVbRiDcIZ'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612806747921
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's test requests:\n",
        "import json\n",
        "import requests\n",
        "\n",
        "scoring_uri = scoring_uri\n",
        "key = key\n",
        "\n",
        "headers = {'Content-Type':'application/json'}\n",
        "headers['Authorization'] = f'Bearer {key}'\n",
        "\n",
        "\n",
        "test_data = json.dumps({'data':[{\n",
        "    'pclass': 0.8419164182590155,\n",
        "    'age': -0.34907541344456255,\n",
        "    'sibsp': -0.47908676070718687,\n",
        "    'parch': -0.444999501816175,\n",
        "    'fare': -0.4902404567566683,\n",
        "    'age_NA': -0.5014319838391105,\n",
        "    'fare_NA': -0.027650063180466557,\n",
        "    'sex_male': 0.743496915331831,\n",
        "    'cabin_Missing': 0.5393765119990418,\n",
        "    'cabin_Rare': -0.42592011250734235,\n",
        "    'embarked_Q': -0.32204029159373954,\n",
        "    'embarked_Rare': -0.03911805059269843,\n",
        "    'embarked_S': 0.6573935670276714,\n",
        "    'title_Mr': 0.8525918887485938,\n",
        "    'title_Mrs': -0.42592011250734235,\n",
        "    'title_Rare': -0.27494677157229536\n",
        "    }\n",
        "    ]\n",
        "        })\n",
        "\n",
        "test_data2 = json.dumps({'data':[{\n",
        "    'pclass': -15460978645168200,\n",
        "    'age': 0.8912042887450313,\n",
        "    'sibsp': -0.47908676070718687,\n",
        "    'parch': -0.444999501816175,\n",
        "    'fare': 19569900306355100,\n",
        "    'age_NA': -0.5014319838391105,\n",
        "    'fare_NA': -0.027650063180466557,\n",
        "    'sex_male': -13449954927569300,\n",
        "    'cabin_Missing': -18539924853119600,\n",
        "    'cabin_Rare': 23478581326275300,\n",
        "    'embarked_Q': -0.32204029159373954,\n",
        "    'embarked_Rare': -0.03911805059269843,\n",
        "    'embarked_S': -15211587854766800,\n",
        "    'title_Mr': -11728941046668400,\n",
        "    'title_Mrs': -0.42592011250734235,\n",
        "    'title_Rare': -0.27494677157229536\n",
        "\n",
        "    }\n",
        "    ]\n",
        "        })\n",
        "\n",
        "\n",
        "response1 = requests.post(scoring_uri, data=test_data, headers=headers)\n",
        "response2 = requests.post(scoring_uri, data=test_data2, headers=headers)\n",
        "\n",
        "print(\"Classification Prediction:\",response1.text)\n",
        "print(\"Classification Prediction:\",response2.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612814619158
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get the environment Details and stored them into a file:\n",
        "f = open(\"env.yml\", \"w\")\n",
        "f.write(env.python.conda_dependencies.serialize_to_string())\n",
        "f.close()\n",
        "\n",
        "print(\"packages\", env.python.conda_dependencies.serialize_to_string())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1612811909768
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete Service:\n",
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}